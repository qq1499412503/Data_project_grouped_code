{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import add, Flatten, MaxPooling2D, Dropout, ZeroPadding2D\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (50000, 1)\n",
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (50000, 10)\n"
     ]
    }
   ],
   "source": [
    "#Load Cifar-10 data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train\n",
    "# Normalize data.\n",
    "input_shape = x_train.shape[1:]\n",
    "def normalizer(x_train, x_test):\n",
    "    x_train = x_train.astype('float32') / 255\n",
    "    x_test = x_test.astype('float32') / 255\n",
    "    return x_train, x_test\n",
    "\n",
    "# If subtract pixel mean is enabled\n",
    "def subtract_pixel_mean(x_train, x_test):\n",
    "    x_train_mean = np.mean(x_train, axis=0)\n",
    "    x_train -= x_train_mean\n",
    "    x_test -= x_train_mean\n",
    "    return x_train, x_test\n",
    "\n",
    "def print_info(x_train, y_train, x_test):\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "    print('y_train shape:', y_train.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "def label_binary(y_train, y_test, num_classes):\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    return y_train, y_test\n",
    "print_info(x_train, y_train, x_test)\n",
    "(x_train, x_test)=normalizer(x_train, x_test)\n",
    "#(x_train, x_test)=subtract_pixel_mean(x_train, x_test)\n",
    "(y_train, y_test)=label_binary(y_train, y_test, 10)\n",
    "print_info(x_train, y_train, x_test)\n",
    "def lr_schedule(epoch):\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def resnet_layer(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "\n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def resnet_v1(input_shape, depth, num_classes=10):\n",
    "\n",
    "    if (depth - 2) % 6 != 0:\n",
    "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
    "    # Start model definition.\n",
    "    num_filters = 16\n",
    "    num_res_blocks = int((depth - 2) / 6)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = resnet_layer(inputs=inputs)\n",
    "    # Instantiate the stack of residual units\n",
    "    for stack in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            strides = 1\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                strides = 2  # downsample\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters,\n",
    "                             strides=strides)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters,\n",
    "                             activation=None)\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "            x = Activation('relu')(x)\n",
    "        num_filters *= 2\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v1 does not use BN after last shortcut connection-ReLU\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n"
     ]
    }
   ],
   "source": [
    "model = resnet_v1(input_shape=input_shape, depth=32)\n",
    "#optimizer=Adam(lr=lr_schedule(0))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=lr_schedule(0)),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 2.2806 - acc: 0.2632 - val_loss: 2.0653 - val_acc: 0.3294\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.9966 - acc: 0.3527 - val_loss: 1.8982 - val_acc: 0.3897\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.8813 - acc: 0.3943 - val_loss: 1.8119 - val_acc: 0.4209\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 1.8104 - acc: 0.4218 - val_loss: 1.7573 - val_acc: 0.4406\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 1.7600 - acc: 0.4417 - val_loss: 1.7192 - val_acc: 0.4581\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 1.7079 - acc: 0.4641 - val_loss: 1.6655 - val_acc: 0.4741\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 1.6637 - acc: 0.4829 - val_loss: 1.6205 - val_acc: 0.4935\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 1.6300 - acc: 0.4956 - val_loss: 1.5972 - val_acc: 0.5044\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 1.5972 - acc: 0.5061 - val_loss: 1.5695 - val_acc: 0.5195\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 59s 1ms/step - loss: 1.5720 - acc: 0.5176 - val_loss: 1.5473 - val_acc: 0.5171\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 59s 1ms/step - loss: 1.5494 - acc: 0.5266 - val_loss: 1.5243 - val_acc: 0.5342\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 59s 1ms/step - loss: 1.5219 - acc: 0.5363 - val_loss: 1.5158 - val_acc: 0.5384\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 1.4990 - acc: 0.5471 - val_loss: 1.4819 - val_acc: 0.5488\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 59s 1ms/step - loss: 1.4777 - acc: 0.5544 - val_loss: 1.4741 - val_acc: 0.5510\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 59s 1ms/step - loss: 1.4628 - acc: 0.5611 - val_loss: 1.4513 - val_acc: 0.5580\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 1.4409 - acc: 0.5686 - val_loss: 1.4421 - val_acc: 0.5636\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 1.4241 - acc: 0.5748 - val_loss: 1.4289 - val_acc: 0.5688\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 1.4061 - acc: 0.5826 - val_loss: 1.4102 - val_acc: 0.5778\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 1.3900 - acc: 0.5881 - val_loss: 1.4084 - val_acc: 0.5750\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 1.3758 - acc: 0.5941 - val_loss: 1.4223 - val_acc: 0.5716\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 1.3593 - acc: 0.5991 - val_loss: 1.3778 - val_acc: 0.5892\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 1.3433 - acc: 0.6063 - val_loss: 1.3836 - val_acc: 0.5885\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 1.3290 - acc: 0.6140 - val_loss: 1.3697 - val_acc: 0.5909\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 1.3162 - acc: 0.6161 - val_loss: 1.3892 - val_acc: 0.5846\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 1.3022 - acc: 0.6220 - val_loss: 1.3591 - val_acc: 0.5956\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 1.2879 - acc: 0.6269 - val_loss: 1.3629 - val_acc: 0.5978\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 1.2795 - acc: 0.6282 - val_loss: 1.3162 - val_acc: 0.6131\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 1.2639 - acc: 0.6341 - val_loss: 1.3197 - val_acc: 0.6114\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 1.2508 - acc: 0.6400 - val_loss: 1.3572 - val_acc: 0.6015\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 1.2407 - acc: 0.6425 - val_loss: 1.3310 - val_acc: 0.6072\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 1.2299 - acc: 0.6485 - val_loss: 1.3005 - val_acc: 0.6212\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 1.2148 - acc: 0.6527 - val_loss: 1.2935 - val_acc: 0.6260\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 1.2049 - acc: 0.6549 - val_loss: 1.2854 - val_acc: 0.6258\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 1.1945 - acc: 0.6607 - val_loss: 1.2923 - val_acc: 0.6267\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 1.1824 - acc: 0.6633 - val_loss: 1.2779 - val_acc: 0.6317\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 1.1716 - acc: 0.6696 - val_loss: 1.2611 - val_acc: 0.6341\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 1.1640 - acc: 0.6726 - val_loss: 1.2579 - val_acc: 0.6388\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 1.1503 - acc: 0.6777 - val_loss: 1.2678 - val_acc: 0.6344\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 1.1422 - acc: 0.6786 - val_loss: 1.2563 - val_acc: 0.6384\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 1.1299 - acc: 0.6847 - val_loss: 1.2525 - val_acc: 0.6424\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 1.1139 - acc: 0.6894 - val_loss: 1.2397 - val_acc: 0.6439\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 1.1090 - acc: 0.6918 - val_loss: 1.2678 - val_acc: 0.6404\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 1.1028 - acc: 0.6933 - val_loss: 1.2423 - val_acc: 0.6441\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 1.0875 - acc: 0.7003 - val_loss: 1.2711 - val_acc: 0.6380\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 1.0826 - acc: 0.7010 - val_loss: 1.2472 - val_acc: 0.6434\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 1.0737 - acc: 0.7041 - val_loss: 1.2325 - val_acc: 0.6506\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 1.0621 - acc: 0.7090 - val_loss: 1.2502 - val_acc: 0.6443\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 1.0533 - acc: 0.7120 - val_loss: 1.2502 - val_acc: 0.6467\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 1.0416 - acc: 0.7149 - val_loss: 1.2309 - val_acc: 0.6534\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 1.0313 - acc: 0.7182 - val_loss: 1.2232 - val_acc: 0.6471\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models = model.fit(x_train, y_train,\n",
    "              batch_size=32,\n",
    "              epochs=50,\n",
    "          validation_data=(x_test, y_test),\n",
    "              )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        # set input mean to 0 over the dataset\n",
    "        featurewise_center=False,\n",
    "        # set each sample mean to 0\n",
    "        samplewise_center=False,\n",
    "        # divide inputs by std of dataset\n",
    "        featurewise_std_normalization=False,\n",
    "        # divide each input by its std\n",
    "        samplewise_std_normalization=False,\n",
    "        # apply ZCA whitening\n",
    "        zca_whitening=False,\n",
    "        # epsilon for ZCA whitening\n",
    "        zca_epsilon=1e-06,\n",
    "        # randomly rotate images in the range (deg 0 to 180)\n",
    "        rotation_range=0,\n",
    "        # randomly shift images horizontally\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically\n",
    "        height_shift_range=0.1,\n",
    "        # set range for random shear\n",
    "        shear_range=0.,\n",
    "        # set range for random zoom\n",
    "        zoom_range=0.,\n",
    "        # set range for random channel shifts\n",
    "        channel_shift_range=0.,\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        # value used for fill_mode = \"constant\"\n",
    "        cval=0.,\n",
    "        # randomly flip images\n",
    "        horizontal_flip=True,\n",
    "        # randomly flip images\n",
    "        vertical_flip=False,\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "#datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=16),\n",
    "                        validation_data=(x_test, y_test),\n",
    "                    steps_per_epoch=1,\n",
    "                        epochs=200, verbose=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Evaluating model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.62      0.73      0.67      1000\n",
      "  automobile       0.75      0.82      0.78      1000\n",
      "        bird       0.50      0.55      0.53      1000\n",
      "         cat       0.50      0.35      0.41      1000\n",
      "        deer       0.51      0.66      0.58      1000\n",
      "         dog       0.58      0.53      0.55      1000\n",
      "        frog       0.78      0.65      0.71      1000\n",
      "       horse       0.68      0.73      0.70      1000\n",
      "        ship       0.78      0.76      0.77      1000\n",
      "       truck       0.81      0.68      0.74      1000\n",
      "\n",
      "    accuracy                           0.65     10000\n",
      "   macro avg       0.65      0.65      0.65     10000\n",
      "weighted avg       0.65      0.65      0.65     10000\n",
      "\n",
      "[[727  37  67   9  17   2   5  21  87  28]\n",
      " [ 40 825   6   7   8   5   3   7  31  68]\n",
      " [ 95   5 550  45 139  48  43  56  12   7]\n",
      " [ 48   9 132 351 110 202  70  45  20  13]\n",
      " [ 27   8 103  33 662  30  38  88  10   1]\n",
      " [ 19   7  85 160  89 528  14  81  12   5]\n",
      " [ 19   4  81  55 138  27 648  10  12   6]\n",
      " [ 28   2  45  24  95  58   2 735   2   9]\n",
      " [120  46  18   7  14   4   4   7 761  19]\n",
      " [ 53 159   8   6  17   4   5  37  27 684]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = model.predict(x_test, batch_size=16)\n",
    "print('[INFO] Evaluating model')\n",
    "from sklearn.metrics import classification_report\n",
    "result = classification_report(y_test.argmax(axis=1), predictions.argmax(axis=1),\n",
    "                            target_names=['airplane', 'automobile', 'bird',\n",
    "                                          'cat','deer','dog','frog','horse','ship','truck'])\n",
    "print(result)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test.argmax(axis=1), predictions.argmax(axis=1))\n",
    "print(cm)\n",
    "name1='class_report'\n",
    "with open(str(name1)+\".txt\", \"w\") as f:\n",
    "    f.write(result)\n",
    "name3=cm\n",
    "#with open(str(name3)+\".txt\", \"w\") as f:\n",
    "#    f.write(CM)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "N = np.arange(0, 50)\n",
    "plt.style.use('ggplot')\n",
    "plt.figure()\n",
    "plt.plot(N, models.history['loss'], label='train_loss')\n",
    "plt.plot(N, models.history['val_loss'], label='val_loss')\n",
    "#plt.plot(N, models.history['acc'], label='train_acc')\n",
    "#plt.plot(N, models.history['val_acc'], label='val_acc')\n",
    "plt.title('Training loss and Accuracy')\n",
    "plt.xlabel('epoch #')\n",
    "plt.ylabel('loss/accuracy')\n",
    "plt.ylim((0, 10))\n",
    "plt.legend()\n",
    "name2='img'\n",
    "plt.savefig(str(name2)+'.png')\n",
    "#model.save(sys.args['model'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 188us/step\n",
      "Test loss: 1.117284504699707\n",
      "Test accuracy: 0.7968\n"
     ]
    }
   ],
   "source": [
    "model_type = 'ResNet%dv%d' % (32, 1)\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'cifar10_%s_model.h5' % model_type\n",
    "\n",
    "\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to load a weight file containing 41 layers into a model with 0 layers.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-b7bf07ad0b9d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./saved_models/cifar10_ResNet32v1_model.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[0;32m   1164\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1165\u001b[0m                 saving.load_weights_from_hdf5_group(\n\u001b[1;32m-> 1166\u001b[1;33m                     f, self.layers, reshape=reshape)\n\u001b[0m\u001b[0;32m   1167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, layers, reshape)\u001b[0m\n\u001b[0;32m   1028\u001b[0m                          \u001b[1;34m'containing '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1029\u001b[0m                          \u001b[1;34m' layers into a model with '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1030\u001b[1;33m                          str(len(filtered_layers)) + ' layers.')\n\u001b[0m\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m     \u001b[1;31m# We batch weight value assignments in a single backend call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: You are trying to load a weight file containing 41 layers into a model with 0 layers."
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "model2 = Sequential()\n",
    "model2.load_weights(\"./saved_models/cifar10_ResNet32v1_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
