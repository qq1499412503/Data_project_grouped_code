{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Train data:  (50000, 32, 32, 3)\nTrain filenames:  (50000,)\nTrain labels:  (50000,)\nTest data:  (10000, 32, 32, 3)\nTest filenames:  (10000,)\nTest labels:  (10000,)\nLabel names:  (10,)\n",
      "[[[[158 112  49]\n   [159 111  47]\n   [165 116  51]\n   ...\n   [137  95  36]\n   [126  91  36]\n   [116  85  33]]\n\n  [[152 112  51]\n   [151 110  40]\n   [159 114  45]\n   ...\n   [136  95  31]\n   [125  91  32]\n   [119  88  34]]\n\n  [[151 110  47]\n   [151 109  33]\n   [158 111  36]\n   ...\n   [139  98  34]\n   [130  95  34]\n   [120  89  33]]\n\n  ...\n\n  [[ 68 124 177]\n   [ 42 100 148]\n   [ 31  88 137]\n   ...\n   [ 38  97 146]\n   [ 13  64 108]\n   [ 40  85 127]]\n\n  [[ 61 116 168]\n   [ 49 102 148]\n   [ 35  85 132]\n   ...\n   [ 26  82 130]\n   [ 29  82 126]\n   [ 20  64 107]]\n\n  [[ 54 107 160]\n   [ 56 105 149]\n   [ 45  89 132]\n   ...\n   [ 24  77 124]\n   [ 34  84 129]\n   [ 21  67 110]]]\n\n\n [[[235 235 235]\n   [231 231 231]\n   [232 232 232]\n   ...\n   [233 233 233]\n   [233 233 233]\n   [232 232 232]]\n\n  [[238 238 238]\n   [235 235 235]\n   [235 235 235]\n   ...\n   [236 236 236]\n   [236 236 236]\n   [235 235 235]]\n\n  [[237 237 237]\n   [234 234 234]\n   [234 234 234]\n   ...\n   [235 235 235]\n   [235 235 235]\n   [234 234 234]]\n\n  ...\n\n  [[ 87  99  89]\n   [ 43  51  37]\n   [ 19  23  11]\n   ...\n   [169 184 179]\n   [182 197 193]\n   [188 202 201]]\n\n  [[ 82  96  82]\n   [ 46  57  36]\n   [ 36  44  22]\n   ...\n   [174 189 183]\n   [185 200 196]\n   [187 202 200]]\n\n  [[ 85 101  83]\n   [ 62  75  48]\n   [ 58  67  38]\n   ...\n   [168 183 178]\n   [180 195 191]\n   [186 200 199]]]\n\n\n [[[158 190 222]\n   [158 187 218]\n   [139 166 194]\n   ...\n   [228 231 234]\n   [237 239 243]\n   [238 241 246]]\n\n  [[170 200 229]\n   [172 199 226]\n   [151 176 201]\n   ...\n   [232 232 236]\n   [246 246 250]\n   [246 247 251]]\n\n  [[174 201 225]\n   [176 200 222]\n   [157 179 199]\n   ...\n   [230 229 232]\n   [250 249 251]\n   [245 244 247]]\n\n  ...\n\n  [[ 31  40  45]\n   [ 30  39  44]\n   [ 26  35  40]\n   ...\n   [ 37  40  46]\n   [  9  13  14]\n   [  4   7   5]]\n\n  [[ 23  34  39]\n   [ 27  38  43]\n   [ 25  36  41]\n   ...\n   [ 19  20  24]\n   [  4   6   3]\n   [  5   7   3]]\n\n  [[ 28  41  47]\n   [ 30  43  50]\n   [ 32  45  52]\n   ...\n   [  5   6   8]\n   [  4   5   3]\n   [  7   8   7]]]\n\n\n ...\n\n\n [[[ 20  15  12]\n   [ 19  14  11]\n   [ 15  14  11]\n   ...\n   [ 10   9   7]\n   [ 12  11   9]\n   [ 13  12  10]]\n\n  [[ 21  16  13]\n   [ 20  16  13]\n   [ 18  17  12]\n   ...\n   [ 10   9   7]\n   [ 10   9   7]\n   [ 12  11   9]]\n\n  [[ 21  16  13]\n   [ 21  17  12]\n   [ 20  18  11]\n   ...\n   [ 12  11   9]\n   [ 12  11   9]\n   [ 13  12  10]]\n\n  ...\n\n  [[ 33  25  13]\n   [ 34  26  15]\n   [ 34  26  15]\n   ...\n   [ 28  25  52]\n   [ 29  25  58]\n   [ 23  20  42]]\n\n  [[ 33  25  14]\n   [ 34  26  15]\n   [ 34  26  15]\n   ...\n   [ 27  24  52]\n   [ 27  24  56]\n   [ 25  22  47]]\n\n  [[ 31  23  12]\n   [ 32  24  13]\n   [ 33  25  14]\n   ...\n   [ 24  23  50]\n   [ 26  23  53]\n   [ 25  20  47]]]\n\n\n [[[ 25  40  12]\n   [ 15  36   3]\n   [ 23  41  18]\n   ...\n   [ 61  82  78]\n   [ 92 113 112]\n   [ 75  89  92]]\n\n  [[ 12  25   6]\n   [ 20  37   7]\n   [ 24  36  15]\n   ...\n   [115 134 138]\n   [149 168 177]\n   [104 117 131]]\n\n  [[ 12  25  11]\n   [ 15  29   6]\n   [ 34  40  24]\n   ...\n   [154 172 182]\n   [157 175 192]\n   [116 129 151]]\n\n  ...\n\n  [[100 129  81]\n   [103 132  84]\n   [104 134  86]\n   ...\n   [ 97 128  84]\n   [ 98 126  84]\n   [ 91 121  79]]\n\n  [[103 132  83]\n   [104 131  83]\n   [107 135  87]\n   ...\n   [101 132  87]\n   [ 99 127  84]\n   [ 92 121  79]]\n\n  [[ 95 126  78]\n   [ 95 123  76]\n   [101 128  81]\n   ...\n   [ 93 124  80]\n   [ 95 123  81]\n   [ 92 120  80]]]\n\n\n [[[ 73  78  75]\n   [ 98 103 113]\n   [ 99 106 114]\n   ...\n   [135 150 152]\n   [135 149 154]\n   [203 215 223]]\n\n  [[ 69  73  70]\n   [ 84  89  97]\n   [ 68  75  81]\n   ...\n   [ 85  95  89]\n   [ 71  82  80]\n   [120 133 135]]\n\n  [[ 69  73  70]\n   [ 90  95 100]\n   [ 62  71  74]\n   ...\n   [ 74  81  70]\n   [ 53  62  54]\n   [ 62  74  69]]\n\n  ...\n\n  [[123 128  96]\n   [132 132 102]\n   [129 128 100]\n   ...\n   [108 107  88]\n   [ 62  60  55]\n   [ 27  27  28]]\n\n  [[115 121  91]\n   [123 124  95]\n   [129 126  99]\n   ...\n   [115 116  94]\n   [ 66  65  59]\n   [ 27  27  27]]\n\n  [[116 120  90]\n   [121 122  94]\n   [129 128 101]\n   ...\n   [116 115  94]\n   [ 68  65  58]\n   [ 27  26  26]]]]\n",
      "Learning rate:  0.001\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_5 (InputLayer)            (None, 32, 32, 3)    0                                            \n__________________________________________________________________________________________________",
      "\nconv2d_115 (Conv2D)             (None, 32, 32, 16)   448         input_5[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization_111 (BatchN (None, 32, 32, 16)   64          conv2d_115[0][0]                 \n__________________________________________________________________________________________________\nactivation_39 (Activation)      (None, 32, 32, 16)   0           batch_normalization_111[0][0]    \n__________________________________________________________________________________________________\nconv2d_116 (Conv2D)             (None, 32, 32, 16)   2320        activation_39[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_112 (BatchN (None, 32, 32, 16)   64          conv2d_116[0][0]                 \n__________________________________________________________________________________________________\nactivation_40 (Activation)      (None, 32, 32, 16)   0           batch_normalization_112[0][0]    \n__________________________________________________________________________________________________\nconv2d_117 (Conv2D)             (None, 32, 32, 16)   2320        activation_40[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_113 (BatchN (None, 32, 32, 16)   64          conv2d_117[0][0]                 \n__________________________________________________________________________________________________\nadd_51 (Add)                    (None, 32, 32, 16)   0           activation_39[0][0]              \n                                                                 batch_normalization_113[0][0]    \n__________________________________________________________________________________________________\nactivation_41 (Activation)      (None, 32, 32, 16)   0           add_51[0][0]                     \n__________________________________________________________________________________________________\nconv2d_118 (Conv2D)             (None, 32, 32, 16)   2320        activation_41[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_114 (BatchN (None, 32, 32, 16)   64          conv2d_118[0][0]                 \n__________________________________________________________________________________________________\nactivation_42 (Activation)      (None, 32, 32, 16)   0           batch_normalization_114[0][0]    \n__________________________________________________________________________________________________\nconv2d_119 (Conv2D)             (None, 32, 32, 16)   2320        activation_42[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_115 (BatchN (None, 32, 32, 16)   64          conv2d_119[0][0]                 \n__________________________________________________________________________________________________\nadd_52 (Add)                    (None, 32, 32, 16)   0           activation_41[0][0]              \n                                                                 batch_normalization_115[0][0]    \n__________________________________________________________________________________________________\nactivation_43 (Activation)      (None, 32, 32, 16)   0           add_52[0][0]                     \n__________________________________________________________________________________________________\nconv2d_120 (Conv2D)             (None, 32, 32, 16)   2320        activation_43[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_116 (BatchN (None, 32, 32, 16)   64          conv2d_120[0][0]                 \n__________________________________________________________________________________________________\nactivation_44 (Activation)      (None, 32, 32, 16)   0           batch_normalization_116[0][0]    \n__________________________________________________________________________________________________\nconv2d_121 (Conv2D)             (None, 32, 32, 16)   2320        activation_44[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_117 (BatchN (None, 32, 32, 16)   64          conv2d_121[0][0]                 \n__________________________________________________________________________________________________\nadd_53 (Add)                    (None, 32, 32, 16)   0           activation_43[0][0]              \n                                                                 batch_normalization_117[0][0]    \n__________________________________________________________________________________________________\nactivation_45 (Activation)      (None, 32, 32, 16)   0           add_53[0][0]                     \n__________________________________________________________________________________________________\nconv2d_122 (Conv2D)             (None, 16, 16, 32)   4640        activation_45[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_118 (BatchN (None, 16, 16, 32)   128         conv2d_122[0][0]                 \n__________________________________________________________________________________________________\nactivation_46 (Activation)      (None, 16, 16, 32)   0           batch_normalization_118[0][0]    \n__________________________________________________________________________________________________\nconv2d_123 (Conv2D)             (None, 16, 16, 32)   9248        activation_46[0][0]              \n__________________________________________________________________________________________________\nconv2d_124 (Conv2D)             (None, 16, 16, 32)   544         activation_45[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_119 (BatchN (None, 16, 16, 32)   128         conv2d_123[0][0]                 \n__________________________________________________________________________________________________\nadd_54 (Add)                    (None, 16, 16, 32)   0           conv2d_124[0][0]                 \n                                                                 batch_normalization_119[0][0]    \n__________________________________________________________________________________________________\nactivation_47 (Activation)      (None, 16, 16, 32)   0           add_54[0][0]                     \n__________________________________________________________________________________________________\nconv2d_125 (Conv2D)             (None, 16, 16, 32)   9248        activation_47[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_120 (BatchN (None, 16, 16, 32)   128         conv2d_125[0][0]                 \n__________________________________________________________________________________________________\nactivation_48 (Activation)      (None, 16, 16, 32)   0           batch_normalization_120[0][0]    \n__________________________________________________________________________________________________\nconv2d_126 (Conv2D)             (None, 16, 16, 32)   9248        activation_48[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_121 (BatchN (None, 16, 16, 32)   128         conv2d_126[0][0]                 \n__________________________________________________________________________________________________\nadd_55 (Add)                    (None, 16, 16, 32)   0           activation_47[0][0]              \n                                                                 batch_normalization_121[0][0]    \n__________________________________________________________________________________________________\nactivation_49 (Activation)      (None, 16, 16, 32)   0           add_55[0][0]                     \n__________________________________________________________________________________________________\nconv2d_127 (Conv2D)             (None, 16, 16, 32)   9248        activation_49[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_122 (BatchN (None, 16, 16, 32)   128         conv2d_127[0][0]                 \n__________________________________________________________________________________________________\nactivation_50 (Activation)      (None, 16, 16, 32)   0           batch_normalization_122[0][0]    \n__________________________________________________________________________________________________\nconv2d_128 (Conv2D)             (None, 16, 16, 32)   9248        activation_50[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_123 (BatchN (None, 16, 16, 32)   128         conv2d_128[0][0]                 \n__________________________________________________________________________________________________\nadd_56 (Add)                    (None, 16, 16, 32)   0           activation_49[0][0]              \n                                                                 batch_normalization_123[0][0]    \n__________________________________________________________________________________________________\nactivation_51 (Activation)      (None, 16, 16, 32)   0           add_56[0][0]                     \n__________________________________________________________________________________________________\nconv2d_129 (Conv2D)             (None, 8, 8, 64)     18496       activation_51[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_124 (BatchN (None, 8, 8, 64)     256         conv2d_129[0][0]                 \n__________________________________________________________________________________________________\nactivation_52 (Activation)      (None, 8, 8, 64)     0           batch_normalization_124[0][0]    \n__________________________________________________________________________________________________\nconv2d_130 (Conv2D)             (None, 8, 8, 64)     36928       activation_52[0][0]              \n__________________________________________________________________________________________________\nconv2d_131 (Conv2D)             (None, 8, 8, 64)     2112        activation_51[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_125 (BatchN (None, 8, 8, 64)     256         conv2d_130[0][0]                 \n__________________________________________________________________________________________________\nadd_57 (Add)                    (None, 8, 8, 64)     0           conv2d_131[0][0]                 \n                                                                 batch_normalization_125[0][0]    \n__________________________________________________________________________________________________\nactivation_53 (Activation)      (None, 8, 8, 64)     0           add_57[0][0]                     \n__________________________________________________________________________________________________\nconv2d_132 (Conv2D)             (None, 8, 8, 64)     36928       activation_53[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_126 (BatchN (None, 8, 8, 64)     256         conv2d_132[0][0]                 \n__________________________________________________________________________________________________\nactivation_54 (Activation)      (None, 8, 8, 64)     0           batch_normalization_126[0][0]    \n__________________________________________________________________________________________________\nconv2d_133 (Conv2D)             (None, 8, 8, 64)     36928       activation_54[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_127 (BatchN (None, 8, 8, 64)     256         conv2d_133[0][0]                 \n__________________________________________________________________________________________________\nadd_58 (Add)                    (None, 8, 8, 64)     0           activation_53[0][0]              \n                                                                 batch_normalization_127[0][0]    \n__________________________________________________________________________________________________\nactivation_55 (Activation)      (None, 8, 8, 64)     0           add_58[0][0]                     \n__________________________________________________________________________________________________\nconv2d_134 (Conv2D)             (None, 8, 8, 64)     36928       activation_55[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_128 (BatchN (None, 8, 8, 64)     256         conv2d_134[0][0]                 \n__________________________________________________________________________________________________\nactivation_56 (Activation)      (None, 8, 8, 64)     0           batch_normalization_128[0][0]    \n__________________________________________________________________________________________________\nconv2d_135 (Conv2D)             (None, 8, 8, 64)     36928       activation_56[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_129 (BatchN (None, 8, 8, 64)     256         conv2d_135[0][0]                 \n__________________________________________________________________________________________________\nadd_59 (Add)                    (None, 8, 8, 64)     0           activation_55[0][0]              \n                                                                 batch_normalization_129[0][0]    \n__________________________________________________________________________________________________\nactivation_57 (Activation)      (None, 8, 8, 64)     0           add_59[0][0]                     \n__________________________________________________________________________________________________\naverage_pooling2d_5 (AveragePoo (None, 1, 1, 64)     0           activation_57[0][0]              \n__________________________________________________________________________________________________\nflatten_4 (Flatten)             (None, 64)           0           average_pooling2d_5[0][0]        \n__________________________________________________________________________________________________\ndense_4 (Dense)                 (None, 10)           650         flatten_4[0][0]                  \n==================================================================================================\nTotal params: 274,442\nTrainable params: 273,066\nNon-trainable params: 1,376\n__________________________________________________________________________________________________\nResNet20v1\nUsing real-time data augmentation.\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-cde2fe11e392>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    515\u001b[0m                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m                         callbacks=callbacks)\n\u001b[0m\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[1;31m# Score trained model.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    142\u001b[0m                                      str(validation_data))\n\u001b[0;32m    143\u001b[0m                 val_x, val_y, val_sample_weights = model._standardize_user_data(\n\u001b[1;32m--> 144\u001b[1;33m                     val_x, val_y, val_sample_weight)\n\u001b[0m\u001b[0;32m    145\u001b[0m                 \u001b[0mval_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_x\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mval_y\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mval_sample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m                 if model.uses_learning_phase and not isinstance(K.learning_phase(),\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m                 exception_prefix='target')\n\u001b[0m\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    126\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    129\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected dense_4 to have 2 dimensions, but got array with shape (10000, 10, 10)"
     ],
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_4 to have 2 dimensions, but got array with shape (10000, 10, 10)",
     "output_type": "error"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "import os\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D, AveragePooling2D, concatenate, \\\n",
    "    Activation, ZeroPadding2D, add, Flatten, Convolution2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "#import cifar10\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "\n",
    "\"\"\"\n",
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 \n",
    "training images and 10000 test images.\n",
    "The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains \n",
    "exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random \n",
    "order, but some training batches may contain more images from one class than another. Between them, the training \n",
    "batches contain exactly 5000 images from each class.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def unpickle(file):\n",
    "    \"\"\"load the cifar-10 data\"\"\"\n",
    "\n",
    "    with open(file, 'rb') as fo:\n",
    "        data = pickle.load(fo, encoding='bytes')\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_cifar_10_data(data_dir, negatives=False):\n",
    "    \"\"\"\n",
    "    Return train_data, train_filenames, train_labels, test_data, test_filenames, test_labels\n",
    "    \"\"\"\n",
    "\n",
    "    # get the meta_data_dict\n",
    "    # num_cases_per_batch: 1000\n",
    "    # label_names: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    # num_vis: :3072\n",
    "\n",
    "    meta_data_dict = unpickle(data_dir + \"/batches.meta\")\n",
    "    cifar_label_names = meta_data_dict[b'label_names']\n",
    "    cifar_label_names = np.array(cifar_label_names)\n",
    "\n",
    "    # training data\n",
    "    cifar_train_data = None\n",
    "    cifar_train_filenames = []\n",
    "    cifar_train_labels = []\n",
    "\n",
    "    # cifar_train_data_dict\n",
    "    # 'batch_label': 'training batch 5 of 5'\n",
    "    # 'data': ndarray\n",
    "    # 'filenames': list\n",
    "    # 'labels': list\n",
    "\n",
    "    for i in range(1, 6):\n",
    "        cifar_train_data_dict = unpickle(data_dir + \"/data_batch_{}\".format(i))\n",
    "        if i == 1:\n",
    "            cifar_train_data = cifar_train_data_dict[b'data']\n",
    "        else:\n",
    "            cifar_train_data = np.vstack((cifar_train_data, cifar_train_data_dict[b'data']))\n",
    "        cifar_train_filenames += cifar_train_data_dict[b'filenames']\n",
    "        cifar_train_labels += cifar_train_data_dict[b'labels']\n",
    "\n",
    "    cifar_train_data = cifar_train_data.reshape((len(cifar_train_data), 3, 32, 32))\n",
    "    if negatives:\n",
    "        cifar_train_data = cifar_train_data.transpose(0, 2, 3, 1).astype(np.float32)\n",
    "    else:\n",
    "        cifar_train_data = np.rollaxis(cifar_train_data, 1, 4)\n",
    "    cifar_train_filenames = np.array(cifar_train_filenames)\n",
    "    cifar_train_labels = np.array(cifar_train_labels)\n",
    "\n",
    "    # test data\n",
    "    # cifar_test_data_dict\n",
    "    # 'batch_label': 'testing batch 1 of 1'\n",
    "    # 'data': ndarray\n",
    "    # 'filenames': list\n",
    "    # 'labels': list\n",
    "\n",
    "    cifar_test_data_dict = unpickle(data_dir + \"/test_batch\")\n",
    "    cifar_test_data = cifar_test_data_dict[b'data']\n",
    "    cifar_test_filenames = cifar_test_data_dict[b'filenames']\n",
    "    cifar_test_labels = cifar_test_data_dict[b'labels']\n",
    "\n",
    "    cifar_test_data = cifar_test_data.reshape((len(cifar_test_data), 3, 32, 32))\n",
    "    if negatives:\n",
    "        cifar_test_data = cifar_test_data.transpose(0, 2, 3, 1).astype(np.float32)\n",
    "    else:\n",
    "        cifar_test_data = np.rollaxis(cifar_test_data, 1, 4)\n",
    "    cifar_test_filenames = np.array(cifar_test_filenames)\n",
    "    cifar_test_labels = np.array(cifar_test_labels)\n",
    "\n",
    "    return cifar_train_data, cifar_train_filenames, cifar_train_labels, \\\n",
    "        cifar_test_data, cifar_test_filenames, cifar_test_labels, cifar_label_names\n",
    "\n",
    "\n",
    "cifar_10_dir = 'cifar-10-batches-py'\n",
    "\n",
    "train_data, train_filenames, train_labels, test_data, test_filenames, test_labels, label_names = \\\n",
    "load_cifar_10_data(cifar_10_dir)\n",
    "print(\"Train data: \", train_data.shape)\n",
    "print(\"Train filenames: \", train_filenames.shape)\n",
    "print(\"Train labels: \", train_labels.shape)\n",
    "print(\"Test data: \", test_data.shape)\n",
    "print(\"Test filenames: \", test_filenames.shape)\n",
    "print(\"Test labels: \", test_labels.shape)\n",
    "print(\"Label names: \", label_names.shape)\n",
    "\n",
    "\n",
    "\n",
    "#convert to binary \n",
    "num_classes = 10\n",
    "def binary_label(label, num_class):\n",
    "    return keras.utils.to_categorical(label, num_class)\n",
    "\n",
    "y_train = binary_label(train_labels, num_classes)\n",
    "y_test = binary_label(test_labels, num_classes)\n",
    "\n",
    "def image_normalization(image):\n",
    "    return image.astype('float32')/255\n",
    "\n",
    "x_train = image_normalization(train_data)\n",
    "x_test = image_normalization(test_data)\n",
    "\n",
    "\n",
    "# Subtracting pixel mean improves accuracy\n",
    "subtract_pixel_mean = True\n",
    "\n",
    "\n",
    "\n",
    "# If subtract pixel mean is enabled\n",
    "if subtract_pixel_mean:\n",
    "    x_train_mean = np.mean(x_train, axis=0)\n",
    "    x_train -= x_train_mean\n",
    "    x_test -= x_train_mean\n",
    "\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 32  # orig paper trained all networks with batch_size=128\n",
    "epochs = 200\n",
    "data_augmentation = True\n",
    "num_classes = 10\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "\n",
    "def resnet_layer(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or\n",
    "            bn-activation-conv (False)\n",
    "\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def resnet_v1(input_shape, depth, num_classes=10):\n",
    "    \"\"\"ResNet Version 1 Model builder [a]\n",
    "\n",
    "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
    "    Last ReLU is after the shortcut connection.\n",
    "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, while the number of filters is\n",
    "    doubled. Within each stage, the layers have the same number filters and the\n",
    "    same number of filters.\n",
    "    Features maps sizes:\n",
    "    stage 0: 32x32, 16\n",
    "    stage 1: 16x16, 32\n",
    "    stage 2:  8x8,  64\n",
    "    The Number of parameters is approx the same as Table 6 of [a]:\n",
    "    ResNet20 0.27M\n",
    "    ResNet32 0.46M\n",
    "    ResNet44 0.66M\n",
    "    ResNet56 0.85M\n",
    "    ResNet110 1.7M\n",
    "\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 6 != 0:\n",
    "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
    "    # Start model definition.\n",
    "    num_filters = 16\n",
    "    num_res_blocks = int((depth - 2) / 6)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = resnet_layer(inputs=inputs)\n",
    "    # Instantiate the stack of residual units\n",
    "    for stack in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            strides = 1\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                strides = 2  # downsample\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters,\n",
    "                             strides=strides)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters,\n",
    "                             activation=None)\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "            x = Activation('relu')(x)\n",
    "        num_filters *= 2\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v1 does not use BN after last shortcut connection-ReLU\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet_v2(input_shape, depth, num_classes=10):\n",
    "    \"\"\"ResNet Version 2 Model builder [b]\n",
    "\n",
    "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
    "    bottleneck layer\n",
    "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
    "    Second and onwards shortcut connection is identity.\n",
    "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, while the number of filter maps is\n",
    "    doubled. Within each stage, the layers have the same number filters and the\n",
    "    same filter map sizes.\n",
    "    Features maps sizes:\n",
    "    conv1  : 32x32,  16\n",
    "    stage 0: 32x32,  64\n",
    "    stage 1: 16x16, 128\n",
    "    stage 2:  8x8,  256\n",
    "\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 9 != 0:\n",
    "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
    "    # Start model definition.\n",
    "    num_filters_in = 16\n",
    "    num_res_blocks = int((depth - 2) / 9)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
    "    x = resnet_layer(inputs=inputs,\n",
    "                     num_filters=num_filters_in,\n",
    "                     conv_first=True)\n",
    "\n",
    "    # Instantiate the stack of residual units\n",
    "    for stage in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            activation = 'relu'\n",
    "            batch_normalization = True\n",
    "            strides = 1\n",
    "            if stage == 0:\n",
    "                num_filters_out = num_filters_in * 4\n",
    "                if res_block == 0:  # first layer and first stage\n",
    "                    activation = None\n",
    "                    batch_normalization = False\n",
    "            else:\n",
    "                num_filters_out = num_filters_in * 2\n",
    "                if res_block == 0:  # first layer but not first stage\n",
    "                    strides = 2    # downsample\n",
    "\n",
    "            # bottleneck residual unit\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters_in,\n",
    "                             kernel_size=1,\n",
    "                             strides=strides,\n",
    "                             activation=activation,\n",
    "                             batch_normalization=batch_normalization,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_in,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_out,\n",
    "                             kernel_size=1,\n",
    "                             conv_first=False)\n",
    "            if res_block == 0:\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters_out,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "\n",
    "        num_filters_in = num_filters_out\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v2 has BN-ReLU before Pooling\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "version = 1\n",
    "n=3\n",
    "# Computed depth from supplied model parameter n\n",
    "if version == 1:\n",
    "    depth = n * 6 + 2\n",
    "elif version == 2:\n",
    "    depth = n * 9 + 2\n",
    "model_type = 'ResNet%dv%d' % (depth, version)   \n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "if version == 2:\n",
    "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
    "else:\n",
    "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=lr_schedule(0)),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "print(model_type)\n",
    "\n",
    "# Prepare model model saving directory.\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
    "\n",
    "# Run training, with or without data augmentation.\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=callbacks)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        # set input mean to 0 over the dataset\n",
    "        featurewise_center=False,\n",
    "        # set each sample mean to 0\n",
    "        samplewise_center=False,\n",
    "        # divide inputs by std of dataset\n",
    "        featurewise_std_normalization=False,\n",
    "        # divide each input by its std\n",
    "        samplewise_std_normalization=False,\n",
    "        # apply ZCA whitening\n",
    "        zca_whitening=False,\n",
    "        # epsilon for ZCA whitening\n",
    "        zca_epsilon=1e-06,\n",
    "        # randomly rotate images in the range (deg 0 to 180)\n",
    "        rotation_range=0,\n",
    "        # randomly shift images horizontally\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically\n",
    "        height_shift_range=0.1,\n",
    "        # set range for random shear\n",
    "        shear_range=0.,\n",
    "        # set range for random zoom\n",
    "        zoom_range=0.,\n",
    "        # set range for random channel shifts\n",
    "        channel_shift_range=0.,\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        # value used for fill_mode = \"constant\"\n",
    "        cval=0.,\n",
    "        # randomly flip images\n",
    "        horizontal_flip=True,\n",
    "        # randomly flip images\n",
    "        vertical_flip=False,\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        steps_per_epoch=1,\n",
    "                        epochs=epochs, verbose=1, workers=4,\n",
    "                        callbacks=callbacks)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}